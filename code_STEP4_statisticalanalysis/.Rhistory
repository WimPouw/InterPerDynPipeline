devtools::install_github("FredHasselman/casnet")
devtools::install_github("FredHasselman/casnet")
devtools::install_github("FredHasselman/casnet")
install.packages("casnet")
devtools::install_github("FredHasselman/casnet")
install.packages("tidyverse")
# Update the conflicting package
install.packages("vctrs", repos = "https://cran.rstudio.com/")
# Also update tidyverse to be safe
install.packages("tidyverse", repos = "https://cran.rstudio.com/")
install.packages("vctrs", repos = "https://cran.rstudio.com/")
# Remove and reinstall
remove.packages(c("vctrs", "tidyr", "tidyverse"))
# Restart R
.rs.restartR()
# Reinstall
install.packages(c("vctrs", "tidyr", "tidyverse"), repos = "https://cran.rstudio.com/")
devtools::install_github("FredHasselman/casnet")
# Save session info to a file
sink("R_package_versions_for_smoothness.txt")
sessionInfo()
# Save session info to a file
sink("R_package_versions_for_smoothness.txt")
sessionInfo()
# Save session info to a file
sink("R_package_versions_for_CRQAstatistics.txt")
sessionInfo()
data <- read.csv("../dataoutput_STEP2_features/smoothness_data.csv")
data_cross_culture <- data[1:30,]
# Add a culture grouping variable
data_cross_culture$culture <- ifelse(grepl("cop_y", data_cross_culture$videoID), "Yurakare",
ifelse(grepl("cop_p", data_cross_culture$videoID), "Polish", NA))
# Restructure data into long format
library(dplyr)
library(tidyr)
data_long <- data_cross_culture %>%
filter(!grepl("stab", videoID, ignore.case = TRUE)) %>%
pivot_longer(cols = c(smoothness_p1_proximity, smoothness_p2_proximity),
names_to = "person",
values_to = "jerkiness_value")
# Create a separate data frame to check for stability
yurakare_stab_test <- data_cross_culture[data_cross_culture$culture == "Yurakare", ]
yurakare_stab_test$is_stab <- as.factor(grepl("stab", yurakare_stab_test$videoID, ignore.case = TRUE))
yurakare_stab_test_long <- yurakare_stab_test %>%
pivot_longer(cols = c(smoothness_p1_proximity, smoothness_p2_proximity),
names_to = "person",
values_to = "jerkiness_value")
# Remove the stab tests here
data_cross_culture <- data_cross_culture %>%
filter(!grepl("stab", videoID, ignore.case = TRUE))
library(lme4)
library(lmerTest)
# Simplest model with random intercept
model_stab <- lmer(jerkiness_value ~ is_stab + (1 | videoID), data = yurakare_stab_test_long)
summary(model_stab)
library(lme4)
library(lmerTest)
# Simplest model with random intercept
model_stab <- lmer(jerkiness_value ~ is_stab + (1 | videoID), data = yurakare_stab_test_long)
summary(model_stab)
#library(lme4)
#library(lmerTest)
# Simplest model with random intercept
model1 <- lmer(jerkiness_value ~ culture + (1 | videoID), data = data_long)
summary(model1)
# Model with random intercept and slope for culture
# Model is overspecified
model2 <- lmer(jerkiness_value ~ culture + (1 + culture| videoID), data = data_long)
library(emmeans)
emmeans(model1, pairwise ~ culture, adjust = "bonferroni")
library(ggplot2)
ggplot(data_long, aes(x = culture, y = jerkiness_value, fill = culture)) +
geom_violin(alpha = 0.7, trim = FALSE) +
geom_boxplot(width = 0.2, outlier.shape = NA, alpha = 0.6) +  # Adds boxplot inside violin
geom_jitter(width = 0.2, alpha = 0.5) +
theme_minimal() +
labs(title = "Comparison of Jerkiness in Proximity Between Cultures",
y = "Jerkiness Value", x = "Culture") +
scale_fill_manual(values = c("Yurakare" = "#A6A24F", "Polish" = "#E07A5F"))
# save the plot
ggsave("../images/smoothness_proximity_culture_comparison.png", width = 8, height = 6, dpi = 300)
ggplot(data_cross_culture, aes(x = culture, y = smoothness_distancecom, fill = culture)) +
geom_violin(alpha = 0.7, trim = FALSE) +
geom_boxplot(width = 0.2, outlier.shape = NA, alpha = 0.6) +  # Adds boxplot inside violin
geom_jitter(width = 0.2, alpha = 0.5) +
theme_minimal() +
labs(title = "Comparison of Jerkiness in Distance Between Center of Mass",
y = "Jerkiness Value", x = "Culture") +
scale_fill_manual(values = c("Yurakare" = "#A6A24F", "Polish" = "#E07A5F"))
# save the plot
ggsave("../images/smoothness_distancecom_culture_comparison.png", width = 8, height = 6, dpi = 300)
ggplot(data_cross_culture, aes(x = culture, y = SPARC_smoothness_distancecom, fill = culture)) +
geom_violin(alpha = 0.7, trim = FALSE) +
geom_boxplot(width = 0.2, outlier.shape = NA, alpha = 0.6) +  # Adds boxplot inside violin
geom_jitter(width = 0.2, alpha = 0.5) +
theme_minimal() +
labs(title = "Comparison of SPARC in Distance Between Center of Mass",
y = "Jerkiness Value", x = "Culture") +
scale_fill_manual(values = c("Yurakare" = "#A6A24F", "Polish" = "#E07A5F"))
# save the plot
ggsave("../images/smoothness_sparc_culture_comparison.png", width = 8, height = 6, dpi = 300)
ggplot(data2_augmented, aes(x = days, y = smoothness_distancecom, color = factor(subject_nr))) +
geom_point(alpha = 0.6) +  # Scatter plot with transparency for better visualization
geom_smooth(method = "lm", aes(group = 1), color = "black", linetype = "dashed") +  # Overall regression line
labs(title = "Effect of Age on Jerkiness in Center of Mass Distance",
x = "Age in # of Days",
y = "Smoothness Distance",
color = "Subject ID") +  # Add a label for the color legend
theme_minimal() +
scale_color_viridis_d()  # Use a color scale that's distinct for each subject
# Chunk 1
data <- read.csv("../dataoutput_STEP2_features/smoothness_data.csv")
data_cross_culture <- data[1:30,]
# Add a culture grouping variable
data_cross_culture$culture <- ifelse(grepl("cop_y", data_cross_culture$videoID), "Yurakare",
ifelse(grepl("cop_p", data_cross_culture$videoID), "Polish", NA))
# Restructure data into long format
library(dplyr)
library(tidyr)
data_long <- data_cross_culture %>%
filter(!grepl("stab", videoID, ignore.case = TRUE)) %>%
pivot_longer(cols = c(smoothness_p1_proximity, smoothness_p2_proximity),
names_to = "person",
values_to = "jerkiness_value")
# Create a separate data frame to check for stability
yurakare_stab_test <- data_cross_culture[data_cross_culture$culture == "Yurakare", ]
yurakare_stab_test$is_stab <- as.factor(grepl("stab", yurakare_stab_test$videoID, ignore.case = TRUE))
yurakare_stab_test_long <- yurakare_stab_test %>%
pivot_longer(cols = c(smoothness_p1_proximity, smoothness_p2_proximity),
names_to = "person",
values_to = "jerkiness_value")
# Remove the stab tests here
data_cross_culture <- data_cross_culture %>%
filter(!grepl("stab", videoID, ignore.case = TRUE))
# Chunk 2
library(lme4)
library(lmerTest)
# Simplest model with random intercept
model_stab <- lmer(jerkiness_value ~ is_stab + (1 | videoID), data = yurakare_stab_test_long)
summary(model_stab)
# Chunk 3
#library(lme4)
#library(lmerTest)
# Simplest model with random intercept
model1 <- lmer(jerkiness_value ~ culture + (1 | videoID), data = data_long)
summary(model1)
# Chunk 5
library(emmeans)
emmeans(model1, pairwise ~ culture, adjust = "bonferroni")
# Chunk 6
library(ggplot2)
ggplot(data_long, aes(x = culture, y = jerkiness_value, fill = culture)) +
geom_violin(alpha = 0.7, trim = FALSE) +
geom_boxplot(width = 0.2, outlier.shape = NA, alpha = 0.6) +  # Adds boxplot inside violin
geom_jitter(width = 0.2, alpha = 0.5) +
theme_minimal() +
labs(title = "Comparison of Jerkiness in Proximity Between Cultures",
y = "Jerkiness Value", x = "Culture") +
scale_fill_manual(values = c("Yurakare" = "#A6A24F", "Polish" = "#E07A5F"))
# save the plot
ggsave("../images/smoothness_proximity_culture_comparison.png", width = 8, height = 6, dpi = 300)
# Chunk 7
library(performance)
plot(check_model(model1))
# Chunk 8
library(report)
report(model1)
# Chunk 9
# This doesn't need the long dataset
dis_model <- lm(smoothness_distancecom ~ culture, data=data_cross_culture)
summary(dis_model)
# Chunk 10
emmeans(dis_model, pairwise ~ culture, adjust = "bonferroni")
# Chunk 11
ggplot(data_cross_culture, aes(x = culture, y = smoothness_distancecom, fill = culture)) +
geom_violin(alpha = 0.7, trim = FALSE) +
geom_boxplot(width = 0.2, outlier.shape = NA, alpha = 0.6) +  # Adds boxplot inside violin
geom_jitter(width = 0.2, alpha = 0.5) +
theme_minimal() +
labs(title = "Comparison of Jerkiness in Distance Between Center of Mass",
y = "Jerkiness Value", x = "Culture") +
scale_fill_manual(values = c("Yurakare" = "#A6A24F", "Polish" = "#E07A5F"))
# save the plot
ggsave("../images/smoothness_distancecom_culture_comparison.png", width = 8, height = 6, dpi = 300)
# Chunk 12
library(clubSandwich)
lm_model <- lm(jerkiness_value ~ culture,data = data_long)
vcov <- vcovCR(lm_model,cluster=data_long$videoID, type="CR2")
coef_test(lm_model, vcov=vcov)
# Chunk 13
sparc_model <- lm(SPARC_smoothness_distancecom ~ culture, data=data_cross_culture)
summary(sparc_model)
# Chunk 14
emmeans(sparc_model, pairwise ~ culture, adjust = "bonferroni")
# Chunk 15
ggplot(data_cross_culture, aes(x = culture, y = SPARC_smoothness_distancecom, fill = culture)) +
geom_violin(alpha = 0.7, trim = FALSE) +
geom_boxplot(width = 0.2, outlier.shape = NA, alpha = 0.6) +  # Adds boxplot inside violin
geom_jitter(width = 0.2, alpha = 0.5) +
theme_minimal() +
labs(title = "Comparison of SPARC in Distance Between Center of Mass",
y = "Jerkiness Value", x = "Culture") +
scale_fill_manual(values = c("Yurakare" = "#A6A24F", "Polish" = "#E07A5F"))
# save the plot
ggsave("../images/smoothness_sparc_culture_comparison.png", width = 8, height = 6, dpi = 300)
# Chunk 16
library(TOSTER)
## Proximity
m1 = mean(data_long$jerkiness_value[data_long$culture == "Polish"], na.rm = TRUE)
m2 = mean(data_long$jerkiness_value[data_long$culture == "Yurakare"], na.rm = TRUE)
sd1 = sd(data_long$jerkiness_value[data_long$culture == "Polish"], na.rm = TRUE)
sd2 = mean(data_long$jerkiness_value[data_long$culture == "Yurakare"], na.rm = TRUE)
# Using .2 as an effect size here as we don't have prior experience with this measure and it's a small effect size
tsum_TOST(m1=m1,m2=m1,sd1=sd1,sd2=sd1,n1=10,n2=10,low_eqbound=-0.2, high_eqbound=0.2, alpha = 0.05, var.equal=TRUE)
## COM
m3 = mean(data_cross_culture$smoothness_distancecom[data_cross_culture$culture == "Polish"], na.rm = TRUE)
m4 = mean(data_cross_culture$smoothness_distancecom[data_cross_culture$culture == "Yurakare"], na.rm = TRUE)
sd3 = sd(data_cross_culture$smoothness_distancecom[data_cross_culture$culture == "Polish"], na.rm = TRUE)
sd4 = mean(data_cross_culture$smoothness_distancecom[data_cross_culture$culture == "Yurakare"], na.rm = TRUE)
# Using .2 as an effect size here as we don't have prior experience with this measure and it's a small effect size
tsum_TOST(m1=m3,m2=m4,sd1=sd3,sd2=sd1,n1=10,n2=10,low_eqbound=-0.2, high_eqbound=0.2, alpha = 0.05, var.equal=TRUE)
# Chunk 17
data2 <- data[31:length(data$videoID),]
#Load Metadata file
ages <- read.csv("../meta/project_point_metadata_ages.csv")
# Merge these files
library(stringr)
# Ensure columns are character
ages$subject_nr <- as.character(ages$subject_nr)
data2$videoID <- as.character(data2$videoID)
# Extract relevant information from `videoID`
library(purrr)  # Needed for map_chr()
data2 <- data2 %>%
mutate(
T_value = str_split(videoID, "_") %>% map_chr(~ .x[3]),  # Extracts third element after split
T_value = paste0("T", T_value),  # Converts to "T1", "T2", etc.
point_match = str_extract(videoID, "point_\\d+")  # Extracts "point_X" for matching
)
# Extract "point_X" from subject_nr (to match gender)
ages <- ages %>%
mutate(point_match = str_extract(subject_nr, "point_\\d+"))
# Reshape `ages` from wide to long format, keeping age in days and months
ages_long <- ages %>%
pivot_longer(
cols = matches("age_T[1-7]_(days|mo)"),  # Selects columns like age_T1_days, age_T2_mo
names_to = c("T_value", "Age_Type"),
names_pattern = "age_(T[1-7])_(.+)",  # Extracts "T1", "T2", etc., and type (days/mo)
values_to = "Age_Value"
) %>%
pivot_wider(names_from = Age_Type, values_from = Age_Value)  # Reshape back for separate days/mo columns
#  Merge `data2` with `ages_long` using both `T_value` and `point_match`
data2_augmented <- data2 %>%
left_join(ages_long, by = c("point_match", "T_value"))  # Merge on "point_X" and "T1-T7"
# Add time variable
data2_augmented <- data2_augmented %>%
mutate(time = as.numeric(str_extract(T_value, "\\d+")))
# Chunk 18
model_long_lin <- lmer(smoothness_distancecom ~ days + (1 | subject_nr), data = data2_augmented)
model_long_quad <- lmer(smoothness_distancecom ~ days + I(days^2) + (1 | subject_nr), data = data2_augmented)
model_long_cub <- lmer(smoothness_distancecom ~ days + I(days^2) + I(days^3)+ (1 | subject_nr), data = data2_augmented)
#summary(model_long)
# Alternative plotting method
comp_perf <- compare_performance(model_long_lin, model_long_quad, model_long_cub)
print(plot(comp_perf))
anova(model_long_lin, model_long_quad, model_long_cub)
summary(model_long_lin)
ggplot(data2_augmented, aes(x = days, y = smoothness_distancecom, color = factor(subject_nr))) +
geom_point(alpha = 0.6) +  # Scatter plot with transparency for better visualization
geom_smooth(method = "lm", aes(group = 1), color = "black", linetype = "dashed") +  # Overall regression line
labs(title = "Effect of Age on Jerkiness in Center of Mass Distance",
x = "Age in # of Days",
y = "Smoothness Distance",
color = "Subject ID") +  # Add a label for the color legend
theme_minimal() +
scale_color_viridis_d()  # Use a color scale that's distinct for each subject
# save the plot
ggsave("../images/smoothness_distancecom_longitudinal.png", width = 8, height = 6, dpi = 300)
ggplot(data2_augmented, aes(x = days, y = smoothness_distancecom, color = factor(subject_nr), group = subject_nr)) +
geom_point(alpha = 0.6) +  # Scatter plot with transparency for better visualization
geom_line(alpha = 0.6) +  # Add lines for each subject
geom_smooth(method = "lm", aes(group = 1), color = "black", linetype = "dashed") +  # Overall regression line
labs(title = "Effect of Age on Jerkiness in Center of Mass Distance",
x = "Age in # of Days",
y = "Smoothness Distance",
color = "Subject ID") +  # Add a label for the color legend
theme_minimal() +
scale_color_viridis_d()  # Use a color scale that's distinct for each subject
# save the plot
ggsave("../images/smoothness_distancecom_longitudinal_lines.png", width = 8, height = 6, dpi = 300)
data2_augmented <- data2_augmented[!is.na(data2_augmented$days), ] #CHECKBYWIM
orth_model_lin <- lmer(smoothness_distancecom ~ poly(days) + (1 | subject_nr), data = data2_augmented)
orth_model_quad <- lmer(smoothness_distancecom ~ poly(days,2) + (1 | subject_nr), data = data2_augmented)
orth_model_cub <- lmer(smoothness_distancecom ~ poly(days,3) + (1 | subject_nr), data = data2_augmented)
plot(compare_performance(orth_model_lin, orth_model_quad,orth_model_cub))
anova(orth_model_lin, orth_model_quad,orth_model_cub)
summary(orth_model_lin)
model_long_lin_p1 <- lmer(smoothness_p1_proximity ~ days + (1 | subject_nr), data = data2_augmented)
model_long_quad_p1 <- lmer(smoothness_p1_proximity ~ days + I(days^2) + (1 | subject_nr), data = data2_augmented)
model_long_cub_p1 <- lmer(smoothness_p1_proximity ~ days + I(days^2) + I(days^3)+ (1 | subject_nr), data = data2_augmented)
summary(model_long_quad_p1)
plot(compare_performance(model_long_lin_p1, model_long_quad_p1,model_long_cub_p1))
anova(model_long_lin_p1, model_long_quad_p1,model_long_cub_p1)
ggplot(data_cross_culture, aes(x = culture, y = SPARC_smoothness_distancecom, fill = culture)) +
geom_violin(alpha = 0.7, trim = FALSE) +
geom_boxplot(width = 0.2, outlier.shape = NA, alpha = 0.6) +  # Adds boxplot inside violin
geom_jitter(width = 0.2, alpha = 0.5) +
theme_minimal() +
labs(title = "Comparison of SPARC in Distance Between Center of Mass",
y = "Jerkiness Value", x = "Culture") +
scale_fill_manual(values = c("Yurakare" = "#A6A24F", "Polish" = "#E07A5F"))
# save the plot
ggsave("../images/smoothness_sparc_culture_comparison.png", width = 8, height = 6, dpi = 300)
ggplot(data_cross_culture, aes(x = culture, y = SPARC_smoothness_distancecom, fill = culture)) +
geom_violin(alpha = 0.7, trim = FALSE) +
geom_boxplot(width = 0.2, outlier.shape = NA, alpha = 0.6) +  # Adds boxplot inside violin
geom_jitter(width = 0.2, alpha = 0.5) +
theme_minimal() +
labs(title = "Comparison of SPARC in Distance Between Center of Mass",
y = "Jerkiness Value", x = "Culture") +
scale_fill_manual(values = c("Yurakare" = "#A6A24F", "Polish" = "#E07A5F"))
# save the plot
ggsave("../images/smoothness_sparc_culture_comparison.png", width = 8, height = 6, dpi = 300)
ggplot(data_cross_culture, aes(x = culture, y = smoothness_distancecom, fill = culture)) +
geom_violin(alpha = 0.7, trim = FALSE) +
geom_boxplot(width = 0.2, outlier.shape = NA, alpha = 0.6) +  # Adds boxplot inside violin
geom_jitter(width = 0.2, alpha = 0.5) +
theme_minimal() +
labs(title = "Comparison of Jerkiness in Distance Between Center of Mass",
y = "Jerkiness Value", x = "Culture") +
scale_fill_manual(values = c("Yurakare" = "#A6A24F", "Polish" = "#E07A5F"))
# save the plot
ggsave("../images/smoothness_distancecom_culture_comparison.png", width = 8, height = 6, dpi = 300)
data <- read.csv("../dataoutput_STEP2_features/smoothness_data.csv")
data_cross_culture <- data[1:30,]
# Add a culture grouping variable
data_cross_culture$culture <- ifelse(grepl("cop_y", data_cross_culture$videoID), "Yurakare",
ifelse(grepl("cop_p", data_cross_culture$videoID), "Polish", NA))
# Restructure data into long format
library(dplyr)
library(tidyr)
data_long <- data_cross_culture %>%
filter(!grepl("stab", videoID, ignore.case = TRUE)) %>%
pivot_longer(cols = c(smoothness_p1_proximity, smoothness_p2_proximity),
names_to = "person",
values_to = "jerkiness_value")
# Create a separate data frame to check for stability
yurakare_stab_test <- data_cross_culture[data_cross_culture$culture == "Yurakare", ]
yurakare_stab_test$is_stab <- as.factor(grepl("stab", yurakare_stab_test$videoID, ignore.case = TRUE))
yurakare_stab_test_long <- yurakare_stab_test %>%
pivot_longer(cols = c(smoothness_p1_proximity, smoothness_p2_proximity),
names_to = "person",
values_to = "jerkiness_value")
# Remove the stab tests here
data_cross_culture <- data_cross_culture %>%
filter(!grepl("stab", videoID, ignore.case = TRUE))
# Chunk 1: setup
knitr::opts_chunk$set(
fig.align = "center",
fig.height = 7,
fig.width = 10,
message = FALSE,
warning = FALSE,
collapse = FALSE,
comment = ">",
dpi = 72,
tidy = FALSE,
width = 800
)
# Chunk 3: load
# Load packages
library(rio)
library(plyr)
library(tidyverse)
library(casnet) # If you have not installed it: devtools::install_github("FredHasselman/casnet")
library(invctr)
library(fpCompare)
library(gplots)
library(testthat)
library(report)
library(emmeans)
library(sjPlot)
# Paths to files
path_repo <- "../"
path_meta <- file.path(path_repo,"meta")
path_oridata <- file.path(path_repo,"dataoutput_STEP1_2_timeseries")
path_results <- file.path(path_repo,"dataoutput_STEP3_nonlinearstatistics")
# Chunk 4: result
meta_data <- rio::import(file.path(path_meta,"project_point_metadata_ages.csv"))
crqa_data <- rio::import(file.path(path_results, "crqa_results_all.csv"))
# Figures CRQA ----
# Ages and sessions
brk <- round(colMeans(meta_data[,3:9], na.rm = TRUE),1)
lbls <- paste0("S",1:7,"=",brk)
crqa_data |>
group_by(gender_f) |>
summarise(mean = mean(age_days, na.rm = TRUE))
ggplot(crqa_data, aes(x = age_days, y = session, group = subject_nr_n)) +
geom_point(aes(colour = subject_nr, shape = gender_f),position = position_jitter(.4,.1)) +
scale_x_continuous("Age (days)",breaks = brk, labels = lbls) +
theme_bw() +
theme(panel.grid.minor.x = element_blank())
# Chunk 5: raw
# Linear
ggplot(crqa_data, aes(x = age_days, y = DET, group = subject_nr_n)) +
geom_point(aes(fill = subject_nr), pch= 21) +
geom_smooth(aes(colour = subject_nr), method = "lm", se = FALSE) +
theme_bw()
# Square
ggplot(crqa_data, aes(x = age_days, y = DET, group = subject_nr_n)) +
geom_point(aes(fill = subject_nr), pch= 21) +
geom_smooth(aes(colour = subject_nr), method = "lm", formula = "y ~ poly(x, 2)", se = FALSE) +
theme_bw()
# Cube
ggplot(crqa_data, aes(x = age_days, y = DET, group = subject_nr_n)) +
geom_point(aes(fill = subject_nr), pch= 21) +
geom_smooth(aes(colour = subject_nr), method = "lm", formula = "y ~ poly(x, 3)", se = FALSE) +
theme_bw()
# Chunk 6: lmer
library(lme4)
library(lmerTest)
library(emmeans)
library(future)
maxAge <- max(crqa_data$age_days_cS1)
crqa_data$age_days_cS1_u <- crqa_data$age_days_cS1/maxAge
# Linear time >> Yes
g0.1 <- glmer(N_dlp/RP_N ~ poly(age_days_cS1,1) + (1|subject_nr_f), weights = RP_N, family = binomial,crqa_data)
summary(g0.1)
# Random slopes? >> No
g0.2 <- glmer(N_dlp/RP_N ~ poly(age_days_cS1,1) + (poly(age_days_cS1_u,1, raw = TRUE)|subject_nr_f), weights = RP_N, family = binomial,crqa_data)
summary(g0.2)
# Quadratic time trend >> Yes
g0.3 <- glmer(N_dlp/RP_N ~ poly(age_days_cS1,2) + (1|subject_nr_f), weights = RP_N, family = binomial,crqa_data)
summary(g0.3)
anova(g0.1,g0.2,g0.3)
# Chunk 7: lmerGender
# Add gender
g1.4 <- glmer(N_dlp/RP_N ~ gender_f + poly(age_days_cS1,2) + (1|subject_nr_f), weights = RP_N, family = binomial,crqa_data)
summary(g1.4)
# Conditional change model
g1.5 <- glmer(N_dlp/RP_N ~ gender_f * poly(age_days_cS1,2) + (1|subject_nr_f),  weights = RP_N, family = binomial,crqa_data)
saveRDS(g1.5, file = file.path(path_results, "g5_glmer.rds"))
summary(g1.5)
anova(g1.4,g1.5)
crqa_data$predg15 <- predict(g1.5, type = "response")
crqa_data_tmp <- crqa_data %>% filter(subject_nr!="point_14")
# Conditional change model without "Father-Daughter" dyad
g1.6 <- glmer(N_dlp/RP_N ~ gender_f * poly(age_days_cS1,2) + (1|subject_nr_f),  weights = RP_N, family = binomial,crqa_data_tmp)
summary(g1.6)
crqa_data$dyad <- paste("mother -",ifelse(crqa_data$gender_f=="boys", "son","daughter"))
crqa_data$dyad[crqa_data$subject_nr=="point_14"] <- "father - daughter"
crqa_data$dyad_fs <- factor(crqa_data$dyad, c("mother - daughter", "mother - son", "father - daughter"), c("m-d", "m-s", "f-d"))
crqa_data$dyad_fs <- reorder(crqa_data$dyad_fs, ref = "f-d")
# Conditional change model with dyad-caregiver categories
g1.7 <- glmer(N_dlp/RP_N ~ dyad_fs * poly(age_days_cS1,2) + (1|subject_nr_f),  weights = RP_N, family = binomial,crqa_data)
saveRDS(g1.7, file = file.path(path_results, "g7_glmer.rds"))
summary(g1.7)
emmeans::emmeans(g1.7, ~ dyad_fs|poly(age_days_cS1,2), type = "response")
crqa_data$predg17 <- predict(g1.7, type = "response")
crqa_data$dyad <- paste("mother -",ifelse(crqa_data$gender_f=="boys", "son","daughter"))
crqa_data$dyad[crqa_data$subject_nr=="point_14"] <- "father - daughter"
crqa_data$dyad_f <- factor(crqa_data$dyad, c("mother - daughter", "mother - son", "father - daughter"), ordered=TRUE)
ggplot(crqa_data, aes(x = age_days, y = predg17, group = subject_nr_f)) +
geom_smooth(aes(colour = dyad_f), method = "lm", formula = "y ~ poly(x, 2)", se = FALSE) +
geom_point(aes(shape = dyad_f, fill = dyad_f)) +
scale_y_continuous("Predicted Determinism", limits = c(.3,.45), expand = c(0,.01)) +
scale_x_continuous("Age (days)",c(250,300,350,400, 450)) +
scale_fill_manual("Dyad", values = c("steelblue2","thistle2","peachpuff2")) +
scale_colour_manual("Dyad", values = c("steelblue3","thistle3","peachpuff3")) +
scale_shape_manual("Dyad", values = c(21,22,24)) +
theme_bw()
# save figure
ggsave(file.path(path_repo,"images/crqa_determinism_by_dyad.png"), width = 10, height = 7, dpi = 300)
# For the report we need the model fitted on the actual proportion, the form N_dlp/RP_N doesn't work
g1.7a <- glmer(DET ~ dyad_fs * poly(age_days_cS1_u,2, raw = TRUE) + (1|subject_nr_f),  weights = RP_N, family = binomial,crqa_data)
